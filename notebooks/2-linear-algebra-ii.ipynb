{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2-linear-algebra-ii.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rjwashi/ai_source/blob/main/notebooks/2-linear-algebra-ii.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTOLgsbN69-P"
      },
      "source": [
        "# Linear Algebra II: Matrix Operations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqUB9FTRAxd-"
      },
      "source": [
        "This topic, *Linear Algebra II: Matrix Operations*, builds on the basics of linear algebra. It is essential because these intermediate-level manipulations of tensors lie at the heart of most machine learning approaches and are especially predominant in deep learning.\n",
        "\n",
        "Through the measured exposition of theory paired with interactive examples, you’ll develop an understanding of how linear algebra is used to solve for unknown values in high-dimensional spaces as well as to reduce the dimensionality of complex spaces. The content covered in this topic is itself foundational for several other topics in the *Machine Learning Foundations* series, especially *Probability & Information Theory* and *Optimization*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4tBvI88BheF"
      },
      "source": [
        "Over the course of studying this topic, you'll:\n",
        "\n",
        "* Develop a geometric intuition of what’s going on beneath the hood of machine learning algorithms, including those used for deep learning.\n",
        "* Be able to more intimately grasp the details of machine learning papers as well as all of the other subjects that underlie ML, including calculus, statistics, and optimization algorithms.\n",
        "* Reduce the dimensionalty of complex spaces down to their most informative elements with techniques such as eigendecomposition, singular value decomposition, and principal component analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z68nQ0ekCYhF"
      },
      "source": [
        "**Note that this Jupyter notebook is not intended to stand alone. It is the companion code to a lecture or to videos from Jon Krohn's [Machine Learning Foundations](https://github.com/jonkrohn/ML-foundations) series, which offer detail on the following:**\n",
        "\n",
        "*Review of Introductory Linear Algebra*\n",
        "\n",
        "* Modern Linear Algebra Applications\n",
        "* Tensors, Vectors, and Norms\n",
        "* Matrix Multiplication\n",
        "* Matrix Inversion\n",
        "* Identity, Diagonal and Orthogonal Matrices\n",
        "\n",
        "*Segment 2: Eigendecomposition*\n",
        "\n",
        "* Affine Transformation via Matrix Application\n",
        "* Eigenvectors and Eigenvalues\n",
        "* Matrix Determinants\n",
        "* Matrix Decomposition\n",
        "* Applications of Eigendecomposition\n",
        "\n",
        "*Segment 3: Matrix Operations for Machine Learning*\n",
        "\n",
        "* Singular Value Decomposition (SVD)\n",
        "* The Moore-Penrose Pseudoinverse\n",
        "* The Trace Operator\n",
        "* Principal Component Analysis (PCA): A Simple Machine Learning Algorithm\n",
        "* Resources for Further Study of Linear Algebra"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ty8zFJj9j3Ui"
      },
      "source": [
        "## Segment 1: Review of Introductory Linear Algebra"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixvqsCeFj3Uj"
      },
      "source": [
        "import numpy as np\n",
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0LgmflFj3Um"
      },
      "source": [
        "### Vector Transposition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6enkxzMmLWtm"
      },
      "source": [
        "x = np.array([25, 2, 5])\n",
        "x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apVGqjNCLWtp"
      },
      "source": [
        "x.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvLQEylJj3Un"
      },
      "source": [
        "x = np.array([[25, 2, 5]])\n",
        "x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WE7xFVxiLWtu"
      },
      "source": [
        "x.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6XtfKZ8j3Ut"
      },
      "source": [
        "x.T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IN1_aSVQj3Uw"
      },
      "source": [
        "x.T.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-_nrgesj3U4"
      },
      "source": [
        "x_p = torch.tensor([25, 2, 5])\n",
        "x_p"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0YuG9Pmj3U6"
      },
      "source": [
        "x_p.T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_bRLc5wj3U8"
      },
      "source": [
        "x_p.view(3, 1) # \"view\" because we're changing output but not the way x is stored in memory"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "llPpXVPHj3U_"
      },
      "source": [
        "**Return to slides here.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43tlq2huj3U_"
      },
      "source": [
        "## $L^2$ Norm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wF1B2qL1j3VA"
      },
      "source": [
        "x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SW2iYHE8j3VC"
      },
      "source": [
        "(25**2 + 2**2 + 5**2)**(1/2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGiMFU0pj3VE"
      },
      "source": [
        "np.linalg.norm(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YBk8ta2j3VI"
      },
      "source": [
        "So, if units in this 3-dimensional vector space are meters, then the vector $x$ has a length of 25.6m"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjS4_w_Rj3VI"
      },
      "source": [
        "# the following line of code will fail because torch.norm() requires input to be float not integer\n",
        "# torch.norm(p)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgadi8SFj3VK"
      },
      "source": [
        "torch.norm(torch.tensor([25, 2, 5.]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qHti3Xslj3VM"
      },
      "source": [
        "**Return to slides here.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xDLTPutj3VN"
      },
      "source": [
        "### Matrices"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fep93KC7j3VN"
      },
      "source": [
        "X = np.array([[25, 2], [5, 26], [3, 7]])\n",
        "X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_yMqWdSj3VP"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDkn2n92j3VX"
      },
      "source": [
        "X_p = torch.tensor([[25, 2], [5, 26], [3, 7]])\n",
        "X_p"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzpKBCqKj3VY"
      },
      "source": [
        "X_p.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pC1rWTlVj3Vg"
      },
      "source": [
        "### Matrix Transposition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srh333wTj3Vg"
      },
      "source": [
        "X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7siMBsRj3Vi"
      },
      "source": [
        "X.T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YF3iqTkUj3Vk"
      },
      "source": [
        "X_p.T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXo5iD5Xj3Vm"
      },
      "source": [
        "**Return to slides here.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loFYZ-pXj3Vm"
      },
      "source": [
        "### Matrix Multiplication"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BrHCDYrzj3Vm"
      },
      "source": [
        "Scalars are applied to each element of matrix:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yf3WIZ6Jj3Vn"
      },
      "source": [
        "X*3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pk-lY78Nj3Vp"
      },
      "source": [
        "X*3+3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_sJ0NI8j3Vq"
      },
      "source": [
        "X_p*3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jebPN-iPj3Vs"
      },
      "source": [
        "X_p*3+3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-a4o6abYj3Vu"
      },
      "source": [
        "Using the multiplication operator on two tensors of the same size in PyTorch (or Numpy or TensorFlow) applies element-wise operations. This is the **Hadamard product** (denoted by the $\\odot$ operator, e.g., $A \\odot B$) *not* **matrix multiplication**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JtRT2V0cj3Vu"
      },
      "source": [
        "A = np.array([[3, 4], [5, 6], [7, 8]])\n",
        "A"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLJYG8MIj3Vw"
      },
      "source": [
        "X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtXoLfKbj3Vx"
      },
      "source": [
        "X * A"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8T09ZO4ij3Vz"
      },
      "source": [
        "A_p = torch.tensor([[3, 4], [5, 6], [7, 8]])\n",
        "A_p"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBadBzQJj3V1"
      },
      "source": [
        "X_p * A_p"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_4kMhF7j3V4"
      },
      "source": [
        "Matrix multiplication with a vector:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAJEstCLj3V5"
      },
      "source": [
        "b = np.array([1, 2])\n",
        "b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOxK6XEXj3V8"
      },
      "source": [
        "np.dot(A, b) # even though technically dot products is between 2 vectors"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Y3Ohltbj3V-"
      },
      "source": [
        "b_p = torch.tensor([1, 2])\n",
        "b_p"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LioexYZ_j3WB"
      },
      "source": [
        "torch.matmul(A_p, b_p)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Wa5CB28j3WC"
      },
      "source": [
        "Matrix multiplication with two matrices:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8ZXM-T4j3WD"
      },
      "source": [
        "B = np.array([[1, 9], [2, 0]])\n",
        "B"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xE0DA5Xrj3WF"
      },
      "source": [
        "np.dot(A, B) # note first column is same as Xb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBvYO9jFj3WH"
      },
      "source": [
        "B_p = torch.tensor([[1, 9], [2, 0]])\n",
        "B_p"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2nEnn3Mj3WI"
      },
      "source": [
        "torch.matmul(A_p, B_p)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCFqu8LWj3WJ"
      },
      "source": [
        "### Matrix Inversion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hhr16-XVj3WK"
      },
      "source": [
        "X = np.array([[4, 2], [-5, -3]])\n",
        "X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIGmFK9oj3WM"
      },
      "source": [
        "Xinv = np.linalg.inv(X)\n",
        "Xinv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWEFauNsj3WO"
      },
      "source": [
        "y = np.array([4, -7])\n",
        "y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egKyXcZhj3WR"
      },
      "source": [
        "w = np.dot(Xinv, y)\n",
        "w"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-QHJQR5LWvF"
      },
      "source": [
        "Show that $y = Xw$:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-6jEzyRLWvG"
      },
      "source": [
        "np.dot(X, w)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jro-lItLj3WT"
      },
      "source": [
        "X_p = torch.tensor([[4, 2], [-5, -3.]]) # note that torch.inverse() requires floats\n",
        "X_p"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4HfI57Nj3WW"
      },
      "source": [
        "Xinv_p = torch.inverse(X_p)\n",
        "Xinv_p"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dy88LRcyj3WY"
      },
      "source": [
        "y_p = torch.tensor([4, -7.])\n",
        "y_p"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wB3r-ggj3Wa"
      },
      "source": [
        "w_p = torch.matmul(Xinv_p, y_p)\n",
        "w_p"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tksRdg5JLWvQ"
      },
      "source": [
        "torch.matmul(X_p, w_p)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWXikiwFj3Wb"
      },
      "source": [
        "**Return to slides here.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4XpcVX2j3Wc"
      },
      "source": [
        "## Segment 2: Eigendecomposition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vgT25z9fN_E"
      },
      "source": [
        "### Affine Transformation via Matrix Application"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLjGas2ij3Ws"
      },
      "source": [
        "Let's say we have a vector $v$:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZvzKGRkj3Ws"
      },
      "source": [
        "v = np.array([3, 1])\n",
        "v"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4UlRvHvZj3Wt"
      },
      "source": [
        "Let's plot $v$ using my `plot_vectors()` function (which is based on Hadrien Jean's `plotVectors()` function from [this notebook](https://github.com/hadrienj/deepLearningBook-Notes/blob/master/2.7%20Eigendecomposition/2.7%20Eigendecomposition.ipynb), under [MIT license](https://github.com/hadrienj/deepLearningBook-Notes/blob/master/LICENSE))."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hl54713Rj3Wt"
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmyWW7Xvj3Wu"
      },
      "source": [
        "def plot_vectors(vectors, colors):\n",
        "    \"\"\"\n",
        "    Plot one or more vectors in a 2D plane, specifying a color for each.\n",
        "\n",
        "    Arguments\n",
        "    ---------\n",
        "    vectors: list of lists or of arrays\n",
        "        Coordinates of the vectors to plot. For example, [[1, 3], [2, 2]]\n",
        "        contains two vectors to plot, [1, 3] and [2, 2].\n",
        "    colors: list\n",
        "        Colors of the vectors. For instance: ['red', 'blue'] will display the\n",
        "        first vector in red and the second in blue.\n",
        "\n",
        "    Example\n",
        "    -------\n",
        "    plot_vectors([[1, 3], [2, 2]], ['red', 'blue'])\n",
        "    plt.xlim(-1, 4)\n",
        "    plt.ylim(-1, 4)\n",
        "    \"\"\"\n",
        "    plt.figure()\n",
        "    plt.axvline(x=0, color='lightgray')\n",
        "    plt.axhline(y=0, color='lightgray')\n",
        "\n",
        "    for i in range(len(vectors)):\n",
        "        x = np.concatenate([[0,0],vectors[i]])\n",
        "        plt.quiver([x[0]], [x[1]], [x[2]], [x[3]],\n",
        "                   angles='xy', scale_units='xy', scale=1, color=colors[i],)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8uP1xgnLj3Wx"
      },
      "source": [
        "plot_vectors([v], ['lightblue'])\n",
        "plt.xlim(-1, 5)\n",
        "_ = plt.ylim(-1, 5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydGgh5lRj3Wy"
      },
      "source": [
        "\"Applying\" a matrix to a vector (i.e., performing matrix-vector multiplication) can linearly transform the vector, e.g, rotate it or rescale it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ReW9fF-sj3Wy"
      },
      "source": [
        "The identity matrix, introduced earlier, is the exception that proves the rule: Applying an identity matrix does not transform the vector:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0riv3SS8j3Wz"
      },
      "source": [
        "I = np.array([[1, 0], [0, 1]])\n",
        "I"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nc7nn6VDj3W0"
      },
      "source": [
        "Iv = np.dot(I, v)\n",
        "Iv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXQBaq2fj3W1"
      },
      "source": [
        "v == Iv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SP81dIksj3W3"
      },
      "source": [
        "plot_vectors([Iv], ['blue'])\n",
        "plt.xlim(-1, 5)\n",
        "_ = plt.ylim(-1, 5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knI50bEJ8UsQ"
      },
      "source": [
        "In contrast, consider this matrix (let's call it $E$) that flips vectors over the $x$-axis:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTGnNFx48UsR"
      },
      "source": [
        "E = np.array([[1, 0], [0, -1]])\n",
        "E"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6CZbgfT8UsS"
      },
      "source": [
        "Ev = np.dot(E, v)\n",
        "Ev"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hDvoi258UsS"
      },
      "source": [
        "plot_vectors([v, Ev], ['lightblue', 'blue'])\n",
        "plt.xlim(-1, 5)\n",
        "_ = plt.ylim(-3, 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfj26eui8UsS"
      },
      "source": [
        "Or, this matrix, $F$, which flips vectors over the $y$-axis:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5wijvsi8UsT"
      },
      "source": [
        "F = np.array([[-1, 0], [0, 1]])\n",
        "F"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7tQhi2Z8UsT"
      },
      "source": [
        "Fv = np.dot(F, v)\n",
        "Fv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrlgyYFH8UsT"
      },
      "source": [
        "plot_vectors([v, Fv], ['lightblue', 'blue'])\n",
        "plt.xlim(-4, 4)\n",
        "_ = plt.ylim(-1, 5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDVVb2Ty8UsT"
      },
      "source": [
        "Applying a flipping matrix is an example of an **affine transformation**: a change in geometry that may adjust distances or angles between vectors, but preserves parallelism between them.\n",
        "\n",
        "In addition to flipping a matrix over an axis (a.k.a., *reflection*), other common affine transformations include:\n",
        "* *Scaling* (changing the length of vectors)\n",
        "* *Shearing* (example of this on the Mona Lisa coming up shortly)\n",
        "* *Rotation*\n",
        "\n",
        "(See [here](https://stackabuse.com/affine-image-transformations-in-python-with-numpy-pillow-and-opencv/) for an outstanding blog post on affine transformations in Python, including how to apply them to images as well as vectors.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JcdkCchSj3W4"
      },
      "source": [
        "A single matrix can apply multiple affine transforms simultaneously (e.g., flip over an axis and rotate 45 degrees). As an example, let's see what happens when we apply this matrix $A$ to the vector $v$:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-EsIE7cj3W4"
      },
      "source": [
        "A = np.array([[-1, 4], [2, -2]])\n",
        "A"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZ0rxeKTj3W5"
      },
      "source": [
        "Av = np.dot(A, v)\n",
        "Av"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCAfNJ8hj3W7"
      },
      "source": [
        "plot_vectors([v, Av], ['lightblue', 'blue'])\n",
        "plt.xlim(-1, 5)\n",
        "_ = plt.ylim(-1, 5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cMA5yMij3W8"
      },
      "source": [
        "# Another example of applying A:\n",
        "v2 = np.array([2, 1])\n",
        "plot_vectors([v2, np.dot(A, v2)], ['lightgreen', 'green'])\n",
        "plt.xlim(-1, 5)\n",
        "_ = plt.ylim(-1, 5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gRqpCA6qj3W-"
      },
      "source": [
        "We can concatenate several vectors together into a matrix (say, $V$), where each column is a separate vector. Then, whatever linear transformations we apply to $V$ will be independently applied to each column (vector):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsRo3xPFj3W-"
      },
      "source": [
        "v"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQDdsKXNj3XA"
      },
      "source": [
        "# recall that we need to convert array to 2D to transpose into column, e.g.:\n",
        "np.matrix(v).T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zb9cSgjnj3XB"
      },
      "source": [
        "v3 = np.array([-3, -1]) # mirror image of v over both axes\n",
        "v4 = np.array([-1, 1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EsdcEFXYj3XC"
      },
      "source": [
        "V = np.concatenate((np.matrix(v).T,\n",
        "                    np.matrix(v2).T,\n",
        "                    np.matrix(v3).T,\n",
        "                    np.matrix(v4).T),\n",
        "                   axis=1)\n",
        "V"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3CSo0Hrj3XD"
      },
      "source": [
        "IV = np.dot(I, V)\n",
        "IV"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6M61JEWj3XE"
      },
      "source": [
        "AV = np.dot(A, V)\n",
        "AV"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGmvjr85j3XG"
      },
      "source": [
        "# function to convert column of matrix to 1D vector:\n",
        "def vectorfy(mtrx, clmn):\n",
        "    return np.array(mtrx[:,clmn]).reshape(-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2eQ4w83j3XH"
      },
      "source": [
        "vectorfy(V, 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_o4HOgEwj3XI"
      },
      "source": [
        "vectorfy(V, 0) == v"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btsivNB_j3XK"
      },
      "source": [
        "plot_vectors([vectorfy(V, 0), vectorfy(V, 1), vectorfy(V, 2), vectorfy(V, 3),\n",
        "             vectorfy(AV, 0), vectorfy(AV, 1), vectorfy(AV, 2), vectorfy(AV, 3)],\n",
        "            ['lightblue', 'lightgreen', 'lightgray', 'orange',\n",
        "             'blue', 'green', 'gray', 'red'])\n",
        "plt.xlim(-4, 6)\n",
        "_ = plt.ylim(-5, 5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFTcb9xkf3vT"
      },
      "source": [
        "Now that we can appreciate the linear transformation of vectors by matrices, let's move on to working with eigenvectors and eigenvalues...\n",
        "\n",
        "**Return to slides here.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "et4bgYFDj3Wr"
      },
      "source": [
        "### Eigenvectors and Eigenvalues"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4n31lIDpj3XL"
      },
      "source": [
        "An **eigenvector** (*eigen* is German for \"typical\"; we could translate *eigenvector* to \"characteristic vector\") is a special vector $v$ such that when it is transformed by some matrix (let's say $A$), the product $Av$ has the exact same direction as $v$.\n",
        "\n",
        "An **eigenvalue** is a scalar (traditionally represented as $\\lambda$) that simply scales the eigenvector $v$ such that the following equation is satisfied:\n",
        "\n",
        "$Av = \\lambda v$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7zVjpW-j3XL"
      },
      "source": [
        "Easiest way to understand this is to work through an example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GbXJtk1Ej3XL"
      },
      "source": [
        "A"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0t2JsM6Wj3XN"
      },
      "source": [
        "Eigenvectors and eigenvalues can be derived algebraically (e.g., with the [QR algorithm](https://en.wikipedia.org/wiki/QR_algorithm), which was independently developed in the 1950s by both [Vera Kublanovskaya](https://en.wikipedia.org/wiki/Vera_Kublanovskaya) and John Francis), however this is outside scope of the *ML Foundations* series. We'll cheat with NumPy `eig()` method, which returns a tuple of:\n",
        "\n",
        "* a vector of eigenvalues\n",
        "* a matrix of eigenvectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYWmgM7jj3XN"
      },
      "source": [
        "lambdas, V = np.linalg.eig(A)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVUp_p6-j3XO"
      },
      "source": [
        "The matrix contains as many eigenvectors as there are columns of A:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7iHlAMa7j3XO"
      },
      "source": [
        "V # each column is a separate eigenvector v"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EBSmc2JLj3XP"
      },
      "source": [
        "With a corresponding eigenvalue for each eigenvector:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYJbCydNj3XP"
      },
      "source": [
        "lambdas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OoZPiaBMj3XR"
      },
      "source": [
        "Let's confirm that $Av = \\lambda v$ for the first eigenvector:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1QZ57TJj3XR"
      },
      "source": [
        "v = V[:,0]\n",
        "v"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vwkWMiIj3XV"
      },
      "source": [
        "lambduh = lambdas[0] # note that \"lambda\" is reserved term in Python\n",
        "lambduh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Leh9n8QBj3XW"
      },
      "source": [
        "Av = np.dot(A, v)\n",
        "Av"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PROIJU30j3XX"
      },
      "source": [
        "lambduh * v"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bT3vjoQj3XY"
      },
      "source": [
        "plot_vectors([Av, v], ['blue', 'lightblue'])\n",
        "plt.xlim(-1, 2)\n",
        "_ = plt.ylim(-1, 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tKQI4691j3XZ"
      },
      "source": [
        "And again for the second eigenvector of A:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "riOJuqz3j3XZ"
      },
      "source": [
        "v2 = V[:,1]\n",
        "v2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QveeHYhDj3Xa"
      },
      "source": [
        "lambda2 = lambdas[1]\n",
        "lambda2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDk1VoVIj3Xb"
      },
      "source": [
        "Av2 = np.dot(A, v2)\n",
        "Av2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smlYxxgpj3Xc"
      },
      "source": [
        "lambda2 * v2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IigKHp0j3Xd"
      },
      "source": [
        "plot_vectors([Av, v, Av2, v2],\n",
        "            ['blue', 'lightblue', 'green', 'lightgreen'])\n",
        "plt.xlim(-1, 4)\n",
        "_ = plt.ylim(-3, 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VF9uLWjOj3Xe"
      },
      "source": [
        "Using the PyTorch `eig()` method, we can do exactly the same:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcJa6w0mj3Xe"
      },
      "source": [
        "A"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WvCqoRij3Xf"
      },
      "source": [
        "A_p = torch.tensor([[-1, 4], [2, -2.]]) # must be float for PyTorch eig()\n",
        "A_p"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TE1W1lykjHfW"
      },
      "source": [
        "lambdas_cplx, V_cplx = torch.linalg.eig(A_p) # outputs complex numbers because real matrices can have complex eigenvectors"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEIkBb8OjhTk"
      },
      "source": [
        "V_cplx # complex-typed values with \"0.j\" imaginary part are in fact real numbers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycqfObc1pyca"
      },
      "source": [
        "V_p = V_cplx.float()\n",
        "V_p"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9_Ri5MGntlz"
      },
      "source": [
        "v_p = V_p[:,0]\n",
        "v_p"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnjVvGxEqHM6"
      },
      "source": [
        "lambdas_cplx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7bIBSQuoGVk"
      },
      "source": [
        "lambdas_p = lambdas_cplx.float()\n",
        "lambdas_p"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VrYaxNCRj3Xj"
      },
      "source": [
        "lambda_p = lambdas_p[0]\n",
        "lambda_p"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUq1UGH7j3Xl"
      },
      "source": [
        "Av_p = torch.matmul(A_p, v_p) # matmul() expects float-typed tensors\n",
        "Av_p"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "co1VNLIej3Xn"
      },
      "source": [
        "lambda_p * v_p"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1b47vG92j3Xo"
      },
      "source": [
        "v2_p = V_p[:,1]\n",
        "v2_p"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-evpW17j3Xp"
      },
      "source": [
        "lambda2_p = lambdas_p[1]\n",
        "lambda2_p"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2d5gjh2sj3Xq"
      },
      "source": [
        "Av2_p = torch.matmul(A_p.float(), v2_p.float())\n",
        "Av2_p"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-ki3i8dj3Xr"
      },
      "source": [
        "lambda2_p.float() * v2_p.float()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2p8yb_Zj3Xs"
      },
      "source": [
        "plot_vectors([Av_p.numpy(), v_p.numpy(), Av2_p.numpy(), v2_p.numpy()],\n",
        "            ['blue', 'lightblue', 'green', 'lightgreen'])\n",
        "plt.xlim(-1, 4)\n",
        "_ = plt.ylim(-3, 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-HqwyESj3Xt"
      },
      "source": [
        "### Eigenvectors in >2 Dimensions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M01JPwToj3Xt"
      },
      "source": [
        "While plotting gets trickier in higher-dimensional spaces, we can nevertheless find and use eigenvectors with more than two dimensions. Here's a 3D example (there are three dimensions handled over three rows):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWsBDEMgj3Xt"
      },
      "source": [
        "X = np.array([[25, 2, 9], [5, 26, -5], [3, 7, -1]])\n",
        "X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-uUMyRFj3Xv"
      },
      "source": [
        "lambdas_X, V_X = np.linalg.eig(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "virh7GVFj3Xw"
      },
      "source": [
        "V_X # one eigenvector per column of X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yHkmEd0j3Xw"
      },
      "source": [
        "lambdas_X # a corresponding eigenvalue for each eigenvector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qp3qPeUxj3Xy"
      },
      "source": [
        "Confirm $Xv = \\lambda v$ for an example eigenvector:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUEfbThhj3Xy"
      },
      "source": [
        "v_X = V_X[:,0]\n",
        "v_X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhnF5asDj3X0"
      },
      "source": [
        "lambda_X = lambdas_X[0]\n",
        "lambda_X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3bA6vRzj3X1"
      },
      "source": [
        "np.dot(X, v_X) # matrix multiplication"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UfN3hk0Gj3X2"
      },
      "source": [
        "lambda_X * v_X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VcjTZv24j3X3"
      },
      "source": [
        "**Exercises**:\n",
        "\n",
        "1. Use PyTorch to confirm $Xv = \\lambda v$ for the first eigenvector of $X$.\n",
        "2. Confirm $Xv = \\lambda v$ for the remaining eigenvectors of $X$ (you can use NumPy or PyTorch, whichever you prefer)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5z5AdeHKj3X4"
      },
      "source": [
        "**Return to slides here.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F44cMjS8j3Wc"
      },
      "source": [
        "### 2x2 Matrix Determinants"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjsXPZEsj3Wc"
      },
      "source": [
        "X = np.array([[4, 2], [-5, -3]])\n",
        "X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tg8BDzOj3We"
      },
      "source": [
        "np.linalg.det(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87wpY5hUj3Wg"
      },
      "source": [
        "**Return to slides here.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5jp6vkNj3Wg"
      },
      "source": [
        "N = np.array([[-4, 1], [-8, 2]])\n",
        "N"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejdkdN7Lj3Wi"
      },
      "source": [
        "np.linalg.det(N)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbIrtcaCj3Wj"
      },
      "source": [
        "# Uncommenting the following line results in a \"singular matrix\" error\n",
        "# Ninv = np.linalg.inv(N)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBT5VC5Nj3Wl"
      },
      "source": [
        "N = torch.tensor([[-4, 1], [-8, 2.]]) # must use float not int"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQA5g0gGj3Wm"
      },
      "source": [
        "torch.det(N)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBIJB7tfj3Wn"
      },
      "source": [
        "**Return to slides here.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwwoY1k6j3Wn"
      },
      "source": [
        "### Generalizing Determinants"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqjRKaCaj3Wn"
      },
      "source": [
        "X = np.array([[1, 2, 4], [2, -1, 3], [0, 5, 1]])\n",
        "X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uimvv39Nj3Wp"
      },
      "source": [
        "np.linalg.det(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQEG5ad1rmr2"
      },
      "source": [
        "**Return to slides here.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2MIHl4MLWw0"
      },
      "source": [
        "### Determinants & Eigenvalues"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0uEEY2qj3X6"
      },
      "source": [
        "lambdas, V = np.linalg.eig(X)\n",
        "lambdas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41P8dP9Gj3X8"
      },
      "source": [
        "np.product(lambdas)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rf83gqIULWw2"
      },
      "source": [
        "**Return to slides here.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zNOgq7I62YA"
      },
      "source": [
        "Here's $|\\text{det}(X)|$ in NumPy:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7Bleu07j3X-"
      },
      "source": [
        "np.abs(np.linalg.det(X))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZQaYZ0q7Zn2"
      },
      "source": [
        "Let's use a matrix $B$, which is composed of basis vectors, to explore the impact of applying matrices with varying $|\\text{det}(X)|$ values:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMPe8LOXj3X_"
      },
      "source": [
        "B = np.array([[1, 0], [0, 1]])\n",
        "B"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlhnOiNzj3YA"
      },
      "source": [
        "plot_vectors([vectorfy(B, 0), vectorfy(B, 1)],\n",
        "            ['lightblue', 'lightgreen'])\n",
        "plt.xlim(-1, 3)\n",
        "_ = plt.ylim(-1, 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RIkz1gCO7_TW"
      },
      "source": [
        "Let's start by applying the matrix $N$ to $B$, recalling from earlier that $N$ is singular:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fjpem_6Ij3YB"
      },
      "source": [
        "N"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BhgWTvaj3YC"
      },
      "source": [
        "np.linalg.det(N)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3XSySPaj3YE"
      },
      "source": [
        "NB = np.dot(N, B)\n",
        "NB"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLiyz0nxj3YF"
      },
      "source": [
        "plot_vectors([vectorfy(B, 0), vectorfy(B, 1), vectorfy(NB, 0), vectorfy(NB, 1)],\n",
        "            ['lightblue', 'lightgreen', 'blue', 'green'])\n",
        "plt.xlim(-6, 6)\n",
        "_ = plt.ylim(-9, 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ErYF2Ss5zZj"
      },
      "source": [
        "lambdas, V = np.linalg.eig(N)\n",
        "lambdas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLwFZuuN8L78"
      },
      "source": [
        "Aha! If any one of a matrix's eigenvalues is zero, then the product of the eigenvalues must be zero and the determinant must also be zero."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tT6ZmuaN8cwJ"
      },
      "source": [
        "Now let's try applying $I_2$ to $B$:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqEkY-8lj3YH"
      },
      "source": [
        "I"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwmKA0wLj3YI"
      },
      "source": [
        "np.linalg.det(I)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xaIq_dUKj3YJ"
      },
      "source": [
        "IB = np.dot(I, B)\n",
        "IB"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8y6svzaLj3YK"
      },
      "source": [
        "plot_vectors([vectorfy(B, 0), vectorfy(B, 1), vectorfy(IB, 0), vectorfy(IB, 1)],\n",
        "            ['lightblue', 'lightgreen', 'blue', 'green'])\n",
        "plt.xlim(-1, 3)\n",
        "_ = plt.ylim(-1, 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWkwRV_46T-q"
      },
      "source": [
        "lambdas, V = np.linalg.eig(I)\n",
        "lambdas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dfrv5ipF9Nx3"
      },
      "source": [
        "All right, so applying an identity matrix isn't the most exciting operation in the world. Let's now apply this matrix $J$ which is more interesting:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xj4bnqVcj3YL"
      },
      "source": [
        "J = np.array([[-0.5, 0], [0, 2]])\n",
        "J"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2ODTOpAj3YM"
      },
      "source": [
        "np.linalg.det(J)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kHJ7Q2Ij3YN"
      },
      "source": [
        "np.abs(np.linalg.det(J))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABciINQwj3YO"
      },
      "source": [
        "JB = np.dot(J, B)\n",
        "JB"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nWa22ZNj3YO"
      },
      "source": [
        "plot_vectors([vectorfy(B, 0), vectorfy(B, 1), vectorfy(JB, 0), vectorfy(JB, 1)],\n",
        "            ['lightblue', 'lightgreen', 'blue', 'green'])\n",
        "plt.xlim(-1, 3)\n",
        "_ = plt.ylim(-1, 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4GTT7Ja6azt"
      },
      "source": [
        "lambdas, V = np.linalg.eig(J)\n",
        "lambdas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1KENtMQ9g4g"
      },
      "source": [
        "Finally, let's apply the matrix $D$, which scales vectors by doubling along both the $x$ and $y$ axes:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-OI7xBWj3YQ"
      },
      "source": [
        "D = I*2\n",
        "D"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKoTu9sbj3YR"
      },
      "source": [
        "np.linalg.det(D)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTb0o2Ydj3YS"
      },
      "source": [
        "DB = np.dot(D, B)\n",
        "DB"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3J2ou_zSj3YT"
      },
      "source": [
        "plot_vectors([vectorfy(B, 0), vectorfy(B, 1), vectorfy(DB, 0), vectorfy(DB, 1)],\n",
        "            ['lightblue', 'lightgreen', 'blue', 'green'])\n",
        "plt.xlim(-1, 3)\n",
        "_ = plt.ylim(-1, 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTfi_wGC-QCL"
      },
      "source": [
        "lambdas, V = np.linalg.eig(D)\n",
        "lambdas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Av0R8fddj3Yb"
      },
      "source": [
        "**Return to slides here.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXNajp3Ej3Yb"
      },
      "source": [
        "### Eigendecomposition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQt403xbj3Yb"
      },
      "source": [
        "The **eigendecomposition** of some matrix $A$ is\n",
        "\n",
        "$A = V \\Lambda V^{-1}$\n",
        "\n",
        "Where:\n",
        "\n",
        "* As in examples above, $V$ is the concatenation of all the eigenvectors of $A$\n",
        "* $\\Lambda$ (upper-case $\\lambda$) is the diagonal matrix diag($\\lambda$). Note that the convention is to arrange the lambda values in descending order; as a result, the first eigenvalue (and its associated eigenvector) may be a primary characteristic of the matrix $A$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7LmR3YGj3Yb"
      },
      "source": [
        "# This was used earlier as a matrix X; it has nice clean integer eigenvalues...\n",
        "A = np.array([[4, 2], [-5, -3]])\n",
        "A"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37zeBrqhj3Yc"
      },
      "source": [
        "lambdas, V = np.linalg.eig(A)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7LtIIMJj3Yd"
      },
      "source": [
        "V"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1uuRwcdj3Ye"
      },
      "source": [
        "Vinv = np.linalg.inv(V)\n",
        "Vinv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_InHRuS1j3Yf"
      },
      "source": [
        "Lambda = np.diag(lambdas)\n",
        "Lambda"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSBnzTBZj3Yg"
      },
      "source": [
        "Confirm that $A = V \\Lambda V^{-1}$:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pG1E3yLYj3Yg"
      },
      "source": [
        "np.dot(V, np.dot(Lambda, Vinv))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTmKZk8fj3Yh"
      },
      "source": [
        "Eigendecomposition is not possible with all matrices. And in some cases where it is possible, the eigendecomposition involves complex numbers instead of straightforward real numbers.\n",
        "\n",
        "In machine learning, however, we are typically working with real symmetric matrices, which can be conveniently and efficiently decomposed into real-only eigenvectors and real-only eigenvalues. If $A$ is a real symmetric matrix then...\n",
        "\n",
        "$A = Q \\Lambda Q^T$\n",
        "\n",
        "...where $Q$ is analogous to $V$ from the previous equation except that it's special because it's an orthogonal matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpZLd9Ozj3Yh"
      },
      "source": [
        "A = np.array([[2, 1], [1, 2]])\n",
        "A"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJOgExEZj3Yj"
      },
      "source": [
        "lambdas, Q = np.linalg.eig(A)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qouDzN5j3Yk"
      },
      "source": [
        "lambdas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZFyXQzkj3Yl"
      },
      "source": [
        "Lambda = np.diag(lambdas)\n",
        "Lambda"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLXaGoVBj3Yl"
      },
      "source": [
        "Q"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UnOfuIf7j3Yo"
      },
      "source": [
        "Let's confirm $A = Q \\Lambda Q^T$:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4DukMWJj3Yo"
      },
      "source": [
        "np.dot(Q, np.dot(Lambda, Q.T))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_eq_1nssj3Ym"
      },
      "source": [
        "(As a quick aside, we can demostrate that $Q$ is an orthogonal matrix because $Q^TQ = QQ^T = I$.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TcavBhdEj3Ym"
      },
      "source": [
        "np.dot(Q.T, Q)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xup113b8j3Yo"
      },
      "source": [
        "np.dot(Q, Q.T)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdJaTKnsj3Yp"
      },
      "source": [
        "**Exercises**:\n",
        "\n",
        "1. Use PyTorch to decompose the matrix $P$ (below) into its components $V$, $\\Lambda$, and $V^{-1}$. Confirm that $P = V \\Lambda V^{-1}$.\n",
        "2. Use PyTorch to decompose the symmetric matrix $S$ (below) into its components $Q$, $\\Lambda$, and $Q^T$. Confirm that $S = Q \\Lambda Q^T$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RVUCVlvj3Yp"
      },
      "source": [
        "P = torch.tensor([[25, 2, -5], [3, -2, 1], [5, 7, 4.]])\n",
        "P"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjKZ_AWLj3Yq"
      },
      "source": [
        "S = torch.tensor([[25, 2, -5], [2, -2, 1], [-5, 1, 4.]])\n",
        "S"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1OFq3uGaj3Yq"
      },
      "source": [
        "**Return to slides here.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKam0tJOj3Yr"
      },
      "source": [
        "## Segment 3: Matrix Operations for ML"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-wbn7omj3Yr"
      },
      "source": [
        "### Singular Value Decomposition (SVD)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2SHytttj3Yr"
      },
      "source": [
        "As on slides, SVD of matrix $A$ is:\n",
        "\n",
        "$A = UDV^T$\n",
        "\n",
        "Where:\n",
        "\n",
        "* $U$ is an orthogonal $m \\times m$ matrix; its columns are the **left-singular vectors** of $A$.\n",
        "* $V$ is an orthogonal $n \\times n$ matrix; its columns are the **right-singular vectors** of $A$.\n",
        "* $D$ is a diagonal $m \\times n$ matrix; elements along its diagonal are the **singular values** of $A$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7hR4Htdj3Yr"
      },
      "source": [
        "A = np.array([[-1, 2], [3, -2], [5, 7]])\n",
        "A"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihj2XfMQj3Ys"
      },
      "source": [
        "U, d, VT = np.linalg.svd(A) # V is already transposed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUfP2aaTj3Yv"
      },
      "source": [
        "U"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_Fkoarvj3Yw"
      },
      "source": [
        "VT"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNSRDcfsj3Yx"
      },
      "source": [
        "d"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lbxh2rYoj3Yy"
      },
      "source": [
        "np.diag(d)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6JN2VA3GNIP5"
      },
      "source": [
        "$D$ must have the same dimensions as $A$ for $UDV^T$ matrix multiplication to be possible:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V47I3B87j3Y0"
      },
      "source": [
        "D = np.concatenate((np.diag(d), [[0, 0]]), axis=0)\n",
        "D"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9euCs5vvj3Y2"
      },
      "source": [
        "np.dot(U, np.dot(D, VT))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-WCBOzKj3Y3"
      },
      "source": [
        "SVD and eigendecomposition are closely related to each other:\n",
        "\n",
        "* Left-singular vectors of $A$ = eigenvectors of $AA^T$.\n",
        "* Right-singular vectors of $A$ = eigenvectors of $A^TA$.\n",
        "* Non-zero singular values of $A$ = square roots of eigenvalues of $AA^T$ = square roots of eigenvalues of $A^TA$\n",
        "\n",
        "**Exercise**: Using the matrix `P` from the preceding PyTorch exercises, demonstrate that these three SVD-eigendecomposition equations are true."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWEOMqUUj3Y3"
      },
      "source": [
        "### Image Compression via SVD"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XmRvLo_Tj3Y3"
      },
      "source": [
        "The section features code adapted from [Frank Cleary's](https://gist.github.com/frankcleary/4d2bd178708503b556b0)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "luD8Y98Vj3Y3"
      },
      "source": [
        "from PIL import Image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thPmYUx4j3Y4"
      },
      "source": [
        "Fetch photo of Oboe, a terrier, with the book *Deep Learning Illustrated*:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPUItNUVj3Y4"
      },
      "source": [
        "! wget https://raw.githubusercontent.com/jonkrohn/DLTFpT/master/notebooks/oboe-with-book.jpg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lx_Frl6j3Y6"
      },
      "source": [
        "img = Image.open('oboe-with-book.jpg')\n",
        "_ = plt.imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYmg1Fa8j3Y6"
      },
      "source": [
        "Convert image to grayscale so that we don't have to deal with the complexity of multiple color channels:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uki3S6w0j3Y7"
      },
      "source": [
        "imggray = img.convert('LA')\n",
        "_ = plt.imshow(imggray)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVwgrA0Jj3Y9"
      },
      "source": [
        "Convert data into numpy matrix, which doesn't impact image data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHijyFgUj3Y9"
      },
      "source": [
        "imgmat = np.array(list(imggray.getdata(band=0)), float)\n",
        "imgmat.shape = (imggray.size[1], imggray.size[0])\n",
        "imgmat = np.matrix(imgmat)\n",
        "_ = plt.imshow(imgmat, cmap='gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8VCD3lyj3Y-"
      },
      "source": [
        "Calculate SVD of the image:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbBLn2Csj3Y-"
      },
      "source": [
        "U, sigma, V = np.linalg.svd(imgmat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApybkCdLj3Y-"
      },
      "source": [
        "As eigenvalues are arranged in descending order in diag($\\lambda$) so too are singular values, by convention, arranged in descending order in $D$ (or, in this code, diag($\\sigma$)). Thus, the first left-singular vector of $U$ and first right-singular vector of $V$ may represent the most prominent feature of the image:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZTwlhGxj3Y_"
      },
      "source": [
        "reconstimg = np.matrix(U[:, :1]) * np.diag(sigma[:1]) * np.matrix(V[:1, :])\n",
        "_ = plt.imshow(reconstimg, cmap='gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4p2cEqIoj3Y_"
      },
      "source": [
        "Additional singular vectors improve the image quality:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5-6LEbij3ZA"
      },
      "source": [
        "for i in [2, 4, 8, 16, 32, 64]:\n",
        "    reconstimg = np.matrix(U[:, :i]) * np.diag(sigma[:i]) * np.matrix(V[:i, :])\n",
        "    plt.imshow(reconstimg, cmap='gray')\n",
        "    title = \"n = %s\" % i\n",
        "    plt.title(title)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IjfUJ4wNj3ZA"
      },
      "source": [
        "With 64 singular vectors, the image is reconstructed quite well, however the data footprint is much smaller than the original image:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXQy4TzCj3ZB"
      },
      "source": [
        "imgmat.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXJtpYGeLWxz"
      },
      "source": [
        "full_representation = 4032*3024\n",
        "full_representation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOHZXITLLWx1"
      },
      "source": [
        "svd64_rep = 64*4032 + 64 + 64*3024\n",
        "svd64_rep"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwdA6taLj3ZD"
      },
      "source": [
        "svd64_rep/full_representation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_HdtL8p7j3ZD"
      },
      "source": [
        "Specifically, the image represented as 64 singular vectors is 3.7% of the size of the original!\n",
        "\n",
        "Alongside images, we can use singular vectors for dramatic, lossy compression of other types of media files."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lBQnc4uGj3ZE"
      },
      "source": [
        "**Return to slides here.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FEnTYLbBj3ZE"
      },
      "source": [
        "### The Moore-Penrose Pseudoinverse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4_MX4D5j3ZE"
      },
      "source": [
        "Let's calculate the pseudoinverse $A^+$ of some matrix $A$ using the formula from the slides:\n",
        "\n",
        "$A^+ = VD^+U^T$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbbiRcmzj3ZE"
      },
      "source": [
        "A"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFNYVdZ4j3ZF"
      },
      "source": [
        "As shown earlier, the NumPy SVD method returns $U$, $d$, and $V^T$:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6NjgNbjj3ZF"
      },
      "source": [
        "U, d, VT = np.linalg.svd(A)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sROQTAzj3ZG"
      },
      "source": [
        "U"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drDSW-vkj3ZG"
      },
      "source": [
        "VT"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sr3jIv4Jj3ZH"
      },
      "source": [
        "d"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yalmt19j3ZI"
      },
      "source": [
        "To create $D^+$, we first invert the non-zero values of $d$:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEvRLwQfj3ZI"
      },
      "source": [
        "D = np.diag(d)\n",
        "D"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6O2LADtLj3ZJ"
      },
      "source": [
        "1/8.669"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1ZbYtmIj3ZJ"
      },
      "source": [
        "1/4.104"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yO1tNES9j3ZK"
      },
      "source": [
        "...and then we would take the tranpose of the resulting matrix.\n",
        "\n",
        "Because $D$ is a diagonal matrix, this can, however, be done in a single step by inverting $D$:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0sjcP3Ej3ZK"
      },
      "source": [
        "Dinv = np.linalg.inv(D)\n",
        "Dinv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXJnvna-j3ZM"
      },
      "source": [
        "$D^+$ must have the same dimensions as $A^T$ in order for $VD^+U^T$ matrix multiplication to be possible:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ydq0zJHNRZPy"
      },
      "source": [
        "Dplus = np.concatenate((Dinv, np.array([[0, 0]]).T), axis=1)\n",
        "Dplus"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFgtoJUKSRg1"
      },
      "source": [
        "(Recall $D$ must have the same dimensions as $A$ for SVD's $UDV^T$, but for MPP $U$ and $V$ have swapped sides around the diagonal matrix.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Xt4NYHuj3ZO"
      },
      "source": [
        "Now we have everything we need to calculate $A^+$ with $VD^+U^T$:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZtWN_wnij3ZO"
      },
      "source": [
        "np.dot(VT.T, np.dot(Dplus, U.T))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3syT7-hCj3ZP"
      },
      "source": [
        "Working out this derivation is helpful for understanding how Moore-Penrose pseudoinverses work, but unsurprisingly NumPy is loaded with an existing method `pinv()`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fh0nDMeLj3ZP"
      },
      "source": [
        "np.linalg.pinv(A)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNrIfpAij3ZS"
      },
      "source": [
        "**Exercise**\n",
        "\n",
        "Use the `torch.svd()` method to calculate the pseudoinverse of `A_p`, confirming that your result matches the output of `torch.pinverse(A_p)`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2635vlEj3ZS"
      },
      "source": [
        "A_p = torch.tensor([[-1, 2], [3, -2], [5, 7.]])\n",
        "A_p"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZW4SsUOlj3ZT"
      },
      "source": [
        "torch.pinverse(A_p)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlXBgI3Nj3ZT"
      },
      "source": [
        "**Return to slides here.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMnIqjpfj3ZT"
      },
      "source": [
        "For regression problems, we typically have many more cases ($n$, or rows of $X$) than features to predict (columns of $X$). Let's solve a miniature example of such an overdetermined situation.\n",
        "\n",
        "We have eight data points ($n$ = 8):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Ft4PXaTj3ZU"
      },
      "source": [
        "x1 = [0, 1, 2, 3, 4, 5, 6, 7.] # E.g.: Dosage of drug for treating Alzheimer's disease\n",
        "y = [1.86, 1.31, .62, .33, .09, -.67, -1.23, -1.37] # E.g.: Patient's \"forgetfulness score\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HaoEgLTzLWyH"
      },
      "source": [
        "title = 'Clinical Trial'\n",
        "xlabel = 'Drug dosage (mL)'\n",
        "ylabel = 'Forgetfulness'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OiMAISFBj3ZW"
      },
      "source": [
        "fig, ax = plt.subplots()\n",
        "plt.title(title)\n",
        "plt.xlabel(xlabel)\n",
        "plt.ylabel(ylabel)\n",
        "_ = ax.scatter(x1, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWZUFeqzj3ZX"
      },
      "source": [
        "Although it appears there is only one predictor ($x_1$), our model requires a second one (let's call it $x_0$) in order to allow for a $y$-intercept. Without this second variable, the line we fit to the plot would need to pass through the origin (0, 0). The $y$-intercept is constant across all the points so we can set it equal to `1` across the board:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RpAIoxydj3ZX"
      },
      "source": [
        "x0 = np.ones(8)\n",
        "x0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bkwC8Wnj3ZY"
      },
      "source": [
        "Concatenate $x_0$ and $x_1$ into a matrix $X$:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x56TMNFMj3ZY"
      },
      "source": [
        "X = np.concatenate((np.matrix(x0).T, np.matrix(x1).T), axis=1)\n",
        "X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7TomkyCj3ZY"
      },
      "source": [
        "From the slides, we know that we can calculate the weights $w$ using the equation $w = X^+y$:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRYhw-N0j3ZZ"
      },
      "source": [
        "w = np.dot(np.linalg.pinv(X), y)\n",
        "w"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2SoGsRNj3ZZ"
      },
      "source": [
        "The first weight corresponds to the $y$-intercept of the line, which is typically denoted as $b$:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLvuVmBGj3ZZ"
      },
      "source": [
        "b = np.asarray(w).reshape(-1)[0]\n",
        "b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96XCC8Z-j3Za"
      },
      "source": [
        "While the second weight corresponds to the slope of the line, which is typically denoted as $m$:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHTNUSJCj3Za"
      },
      "source": [
        "m = np.asarray(w).reshape(-1)[1]\n",
        "m"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvGCTZRqj3Zc"
      },
      "source": [
        "With the weights we can plot the line to confirm it fits the points:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9SAiUyej3Zc"
      },
      "source": [
        "fig, ax = plt.subplots()\n",
        "\n",
        "plt.title(title)\n",
        "plt.xlabel(xlabel)\n",
        "plt.ylabel(ylabel)\n",
        "\n",
        "ax.scatter(x1, y)\n",
        "\n",
        "x_min, x_max = ax.get_xlim()\n",
        "y_at_xmin = m*x_min + b\n",
        "y_at_xmax = m*x_max + b\n",
        "\n",
        "ax.set_xlim([x_min, x_max])\n",
        "_ = ax.plot([x_min, x_max], [y_at_xmin, y_at_xmax], c='C01')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNJJNtDzSh83"
      },
      "source": [
        "**DO NOT return to slides here. Onward!**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJnSV2afj3Zd"
      },
      "source": [
        "### The Trace Operator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dq9uqorvj3Zd"
      },
      "source": [
        "Denoted as Tr($A$). Simply the sum of the diagonal elements of a matrix: $$\\sum_i A_{i,i}$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOdkry9ij3Zd"
      },
      "source": [
        "A = np.array([[25, 2], [5, 4]])\n",
        "A"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwh8-KTNj3Ze"
      },
      "source": [
        "25 + 4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LxzUu37j3Zf"
      },
      "source": [
        "np.trace(A)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUeQKrYMj3Zg"
      },
      "source": [
        "The trace operator has a number of useful properties that come in handy while rearranging linear algebra equations, e.g.:\n",
        "\n",
        "* Tr($A$) = Tr($A^T$)\n",
        "* Assuming the matrix shapes line up: Tr($ABC$) = Tr($CAB$) = Tr($BCA$)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuKYTjskj3Zg"
      },
      "source": [
        "In particular, the trace operator can provide a convenient way to calculate a matrix's Frobenius norm: $$||A||_F = \\sqrt{\\mathrm{Tr}(AA^\\mathrm{T})}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JcqTZnimj3Zg"
      },
      "source": [
        "**Exercises**\n",
        "\n",
        "With the matrix `A_p` provided below:\n",
        "\n",
        "1. Use the PyTorch trace method to calculate the trace of `A_p`.\n",
        "2. Use the PyTorch Frobenius norm method and the trace method to demonstrate that $||A||_F = \\sqrt{\\mathrm{Tr}(AA^\\mathrm{T})}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQhYWOFvj3Zg"
      },
      "source": [
        "A_p"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QXuZgAUgj3Zh"
      },
      "source": [
        "**Return to slides here.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1rQOXPyaj3Zh"
      },
      "source": [
        "### Principal Component Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3_Etgo4j3Zh"
      },
      "source": [
        "This PCA example code is adapted from [here](https://jupyter.brynmawr.edu/services/public/dblank/CS371%20Cognitive%20Science/2016-Fall/PCA.ipynb)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubl3WdRWj3Zh"
      },
      "source": [
        "from sklearn import datasets\n",
        "iris = datasets.load_iris()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZE2yvfEbj3Zi"
      },
      "source": [
        "iris.data.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fa9fcMl2j3Zi"
      },
      "source": [
        "iris.get(\"feature_names\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8O9xwrOLj3Zj"
      },
      "source": [
        "iris.data[0:6,:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YoodmvRsj3Zj"
      },
      "source": [
        "from sklearn.decomposition import PCA"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PcJwICbtj3Zk"
      },
      "source": [
        "pca = PCA(n_components=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNb6txoIj3Zk"
      },
      "source": [
        "X = pca.fit_transform(iris.data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plS7skQGj3Zl"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wC_j-7Xyj3Zl"
      },
      "source": [
        "X[0:6,:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_aNxFn5j3Zm"
      },
      "source": [
        "_ = plt.scatter(X[:, 0], X[:, 1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTck5c93j3Zm"
      },
      "source": [
        "iris.target.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzGhB6NTj3Zn"
      },
      "source": [
        "iris.target[0:6]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQ8oRWsWj3Zn"
      },
      "source": [
        "unique_elements, counts_elements = np.unique(iris.target, return_counts=True)\n",
        "np.asarray((unique_elements, counts_elements))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAIoVTYWj3Zo"
      },
      "source": [
        "list(iris.target_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JlZX_2vQj3Zo"
      },
      "source": [
        "_ = plt.scatter(X[:, 0], X[:, 1], c=iris.target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1Y8YA2oj3Zp"
      },
      "source": [
        "**Return to slides here.**"
      ]
    }
  ]
}